{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Search_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvZ6kgXgOE3"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95pvdNtfWDBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54ad9ae-b4f2-460e-b303-57f169593107"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "from nltk import word_tokenize\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Activation, Dense, Input, Subtract, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import EarlyStopping, TensorBoard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAcTrK-TgXVL"
      },
      "source": [
        "Import Huffington Post dataset with keywords added from prior step of all articles with their category, link, date of publication and the list of associated key phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XSlu9lUWNOB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7a7db15d-6a40-49b9-bfc2-31b184903f48"
      },
      "source": [
        "df = pd.read_csv('/content/News_Category.csv', converters={'key_words': eval})\n",
        "df.drop(axis=1, labels=['headline', 'authors','short_description'], inplace=True)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>link</th>\n",
              "      <th>date</th>\n",
              "      <th>key_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/troy-new-...</td>\n",
              "      <td>2017-12-26</td>\n",
              "      <td>[dewolf also told news 10 abc reporter lauren ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/native-am...</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>[american civil liberties union attorney claud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hostage-s...</td>\n",
              "      <td>2017-01-10</td>\n",
              "      <td>[tuscaloosa police department spokeswoman teen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/cocaine-c...</td>\n",
              "      <td>2015-09-04</td>\n",
              "      <td>[crime]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/massachus...</td>\n",
              "      <td>2016-05-23</td>\n",
              "      <td>[local television news outlets showed dozens, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ...                                          key_words\n",
              "0    CRIME  ...  [dewolf also told news 10 abc reporter lauren ...\n",
              "1    CRIME  ...  [american civil liberties union attorney claud...\n",
              "2    CRIME  ...  [tuscaloosa police department spokeswoman teen...\n",
              "3    CRIME  ...                                            [crime]\n",
              "4    CRIME  ...  [local television news outlets showed dozens, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5W7VlvmlOya"
      },
      "source": [
        "Producing a list of stop words to remove from keywords list with punctuation and white spaces removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TVc5LnUHeai"
      },
      "source": [
        "stopwords = stopwords.words(\"english\")\n",
        "for i in range(0, len(stopwords)):\n",
        "  stopwords[i] = re.sub(\"[^\\w\\s]\", \"\", stopwords[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ErjLwS0lg-H"
      },
      "source": [
        "Creating sets of ages of articles from publication date, word counts of keyword phrases list of all phrases, count of keyword phrases and appending them to the dataset for each respective article. Also creating an inverse index on each word occuring in the keywords list. Each word is a key in a dictionary with the values being dictionaries with keys of the article that the word appears in and the values of that dictionary being a list of positions the word appears in the keywords list for each article. This allows the articles containing a specific word from a query to be found quickly to make a list of all related articles to the query. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY6vZoSUN0IP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "90d7b544-b380-44af-e19d-21ead006f169"
      },
      "source": [
        "ages = []\n",
        "word_count = []\n",
        "phrase_count = []\n",
        "lemma = WordNetLemmatizer()\n",
        "inverted_index = {}\n",
        "for doc in range(0, len(df.key_words)):\n",
        "  ages.append(2020 - int(df.date[doc][0:4]))\n",
        "  phrase_count.append(len(df.key_words[doc]))\n",
        "  keywords = \" \".join(df.key_words[doc]).lower()\n",
        "  words = word_tokenize(re.sub(\"[^\\w\\s]\", \"\", keywords))\n",
        "  word_count.append(len(words))\n",
        "  for pos in range(0, len(words)):\n",
        "    if words[pos] not in stopwords and words[pos].isalpha():\n",
        "      word = lemma.lemmatize(words[pos])\n",
        "      if inverted_index.get(word) is None:\n",
        "        doc_dict = {}\n",
        "        doc_dict[doc] = [pos]\n",
        "        inverted_index[word] = doc_dict\n",
        "      else:\n",
        "        if inverted_index[word].get(doc) is None:\n",
        "          inverted_index[word][doc] = [pos]\n",
        "        else:\n",
        "          pos_list = inverted_index[word][doc]\n",
        "          pos_list.append(pos)\n",
        "          inverted_index[word][doc] = pos_list\n",
        "          \n",
        "df[\"ages\"] = ages\n",
        "df[\"key_word_count\"] = word_count\n",
        "df[\"key_phase_count\"] = phrase_count\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>link</th>\n",
              "      <th>date</th>\n",
              "      <th>key_words</th>\n",
              "      <th>ages</th>\n",
              "      <th>key_word_count</th>\n",
              "      <th>key_phase_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/troy-new-...</td>\n",
              "      <td>2017-12-26</td>\n",
              "      <td>[dewolf also told news 10 abc reporter lauren ...</td>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/native-am...</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>[american civil liberties union attorney claud...</td>\n",
              "      <td>3</td>\n",
              "      <td>90</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hostage-s...</td>\n",
              "      <td>2017-01-10</td>\n",
              "      <td>[tuscaloosa police department spokeswoman teen...</td>\n",
              "      <td>3</td>\n",
              "      <td>51</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/cocaine-c...</td>\n",
              "      <td>2015-09-04</td>\n",
              "      <td>[crime]</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/massachus...</td>\n",
              "      <td>2016-05-23</td>\n",
              "      <td>[local television news outlets showed dozens, ...</td>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  ... key_phase_count\n",
              "0    CRIME  ...              20\n",
              "1    CRIME  ...              20\n",
              "2    CRIME  ...              20\n",
              "3    CRIME  ...               1\n",
              "4    CRIME  ...              20\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC9SQzyqnD4X"
      },
      "source": [
        "This function takes in a list of words in a user entered query and forms a dictionary of all articles containing a word from the query and its associated count of occurrences of words in the query also contained in the article by using the inverted index from the previous step. It is also determining the amount of similarity of the query to the words occurring in the keyword phrases for each article. For example, if the query was \"Black Lives Matters\" and a phrase in the keywords is also \"Black Lives Matters\" then there is 100% match in addition this would be increment the complete match count that is also being collected. If this phrase occurs multiple times, then the complete count would be incremented for each time there is a complete match. If the keyword phrases only matches to \"Days of Our Lives\", there would only be a 33% match and the complete count would not be increased. The dictionary of related articles is then sorted by the amount of occurences of words in each article and all three of these counts are returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c1BPzKZU_Ml"
      },
      "source": [
        "def run_search(search):\n",
        "  results = {}\n",
        "  positions = {}\n",
        "  for word in search:\n",
        "    if inverted_index.get(word) is not None:\n",
        "      for doc in inverted_index[word]:\n",
        "        if doc not in results:\n",
        "          results[doc] = len(inverted_index[word][doc])\n",
        "          positions[doc] = [inverted_index[word][doc]]\n",
        "        else:\n",
        "          results[doc] = results[doc] + len(inverted_index[word][doc])\n",
        "          positions[doc].append(inverted_index[word][doc])\n",
        "\n",
        "  p_match = {}\n",
        "  complete ={}\n",
        "  search_len = len(search)\n",
        "  for key in positions:\n",
        "    position_len = len(positions[key])\n",
        "    p_match[key] = position_len / search_len\n",
        "    if search_len > 1:\n",
        "      if position_len == search_len:\n",
        "        complete_count = 0\n",
        "        for pos in positions[key][0]:\n",
        "          complete_match = True\n",
        "          for i in range(1, position_len):\n",
        "            if (pos + i) not in positions[key][i]:\n",
        "              complete_match = False\n",
        "              break\n",
        "          complete_count += 1 if complete_match else 0\n",
        "        complete[key] = complete_count\n",
        "      else:\n",
        "        complete[key] = 0\n",
        "  sorted_results = sorted(results.items(), key=lambda item: item[1], reverse=True)\n",
        "  complete_matches = complete if len(search) > 1 else p_match\n",
        "  return ((sorted_results, p_match), complete_matches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92k-2d2rqDAl"
      },
      "source": [
        "The next step is to import a dataset of previous query results to train the search engine model. The dataset contains the id, text and word count of the query; id, phrase count, article age and word count for the associated article; and the match rating, term frequency and complete match count for that article and query pairing. The match rating is how well the article reflected a desirable result to the query. An article that would be expected to be at the top of a search for a query will receive a score of 3-4 where as an unrelated article will get a 0. The match rating is used to determine the y for the model whereas the other data are all features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mulrNNI5PiaS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "9aa76966-c530-4157-a3cc-06859018ab3b"
      },
      "source": [
        "rank_data = pd.read_csv('/content/results_ranks.csv')\n",
        "rank_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>query</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>tf</th>\n",
              "      <th>p_match</th>\n",
              "      <th>complete_count</th>\n",
              "      <th>key_size</th>\n",
              "      <th>phrase_count</th>\n",
              "      <th>search_size</th>\n",
              "      <th>doc_age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Trumps tax returns</td>\n",
              "      <td>2371</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Trumps tax returns</td>\n",
              "      <td>5481</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Trumps tax returns</td>\n",
              "      <td>4324</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Trumps tax returns</td>\n",
              "      <td>2271</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Trumps tax returns</td>\n",
              "      <td>6437</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>9</td>\n",
              "      <td>walmart gift cards</td>\n",
              "      <td>8895</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>9</td>\n",
              "      <td>walmart gift cards</td>\n",
              "      <td>6083</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>9</td>\n",
              "      <td>walmart gift cards</td>\n",
              "      <td>2906</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>9</td>\n",
              "      <td>walmart gift cards</td>\n",
              "      <td>17892</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>9</td>\n",
              "      <td>walmart gift cards</td>\n",
              "      <td>2473</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid               query  doc_id  ...  phrase_count  search_size  doc_age\n",
              "0      1  Trumps tax returns    2371  ...            20            3        4\n",
              "1      1  Trumps tax returns    5481  ...            20            3        4\n",
              "2      1  Trumps tax returns    4324  ...            20            3        5\n",
              "3      1  Trumps tax returns    2271  ...            20            3        3\n",
              "4      1  Trumps tax returns    6437  ...            20            3        4\n",
              "..   ...                 ...     ...  ...           ...          ...      ...\n",
              "175    9  walmart gift cards    8895  ...            20            3        3\n",
              "176    9  walmart gift cards    6083  ...            20            3        3\n",
              "177    9  walmart gift cards    2906  ...            20            3        3\n",
              "178    9  walmart gift cards   17892  ...             3            3        7\n",
              "179    9  walmart gift cards    2473  ...            20            3        2\n",
              "\n",
              "[180 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSQkgiheu9av"
      },
      "source": [
        "Next I randomly split the data in half to create pairings since the model requires pairing to train. The model gives a relative comparison of 2 query results to determine how much more a result should be ranked higher in a list of results than another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-JxjU1pRUSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc4a98e-6597-4767-acd7-990479b9fd51"
      },
      "source": [
        "ranking1, ranking2 = train_test_split(rank_data, test_size=0.5)\n",
        "ranking1.shape, ranking2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((90, 11), (90, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "519YBW4PvNVt"
      },
      "source": [
        "Then we find the difference between each pairing's match rating to provide a y to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hECXuqNRZfrT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "a8e1df62-de2a-4e2a-b992-c9d405607ac7"
      },
      "source": [
        "rank_diff = {\"diff\": []}\n",
        "for i in range(0, len(ranking1.rating)):\n",
        "  rank_diff[\"diff\"].append(ranking1.iloc[i].rating - ranking2.iloc[i].rating)\n",
        "\n",
        "rank_diff_data = pd.DataFrame(rank_diff, columns=rank_diff.keys())\n",
        "rank_diff_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.854239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            diff\n",
              "count  90.000000\n",
              "mean    0.333333\n",
              "std     1.854239\n",
              "min    -4.000000\n",
              "25%    -1.000000\n",
              "50%     0.000000\n",
              "75%     2.000000\n",
              "max     4.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viMrK9q6wD3v"
      },
      "source": [
        "Next, I drop any columns that will not be used by the model for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO1_cJ-5jtsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a28706-278b-4117-e8af-11524bd1583a"
      },
      "source": [
        "ranking1.drop(columns=['rating', 'qid', 'query', 'doc_id'], inplace=True)\n",
        "ranking2.drop(columns=['rating', 'qid', 'query', 'doc_id'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmtVuh1iljex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646aa8d1-7eee-4a28-8d0f-d2f1e5b17a66"
      },
      "source": [
        "ranking1.shape, ranking2.shape, rank_diff_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((90, 7), (90, 7), (90, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU29Z_azwOwL"
      },
      "source": [
        "The model is a Siamese-like model where it uses 2 neural networks to come up with a score that is then passed to another network to find the difference between the 2 networks and use a sigmoidal activation function to determine the relative ranking for the pairing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCxJQYJ-PzNM"
      },
      "source": [
        "def create_base_model(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(64, input_shape=input_shape, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYbio0S8Pzgc"
      },
      "source": [
        "def create_conjoined_model(input_shape, base_model):\n",
        "  input_a = Input(shape=(input_shape[0],input_shape[1],))\n",
        "  input_b = Input(shape=(input_shape[0],input_shape[1],))\n",
        "\n",
        "  rank_diff = Subtract()([base_model(input_a), base_model(input_b)])\n",
        "  output = Activation(\"sigmoid\")(rank_diff)\n",
        "  model = Model(inputs = [input_a, input_b], outputs = output)\n",
        "  model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics='accuracy')\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrCWSNq5MXAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a64e9f-ad36-4838-e6f5-97af2cdf3c22"
      },
      "source": [
        "scoring_model = create_base_model(ranking1.shape)\n",
        "model = create_conjoined_model(ranking1.shape, scoring_model)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 90, 7)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 90, 7)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 90, 1)        3137        input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 90, 1)        0           sequential[0][0]                 \n",
            "                                                                 sequential[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 90, 1)        0           subtract[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 3,137\n",
            "Trainable params: 3,137\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkIB4I9ow0Yq"
      },
      "source": [
        "The model trains very quickly probably due to the small dataset used in training. I have found that the model usually has the best validation accuracy around 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrXb33NukJPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d041b2-b9a2-4967-e881-d2b6dad22d45"
      },
      "source": [
        "history = model.fit([ranking1, ranking2], rank_diff_data, validation_split=0.1, epochs= 200, batch_size=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_1:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_2:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_1:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_2:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.9205 - accuracy: 0.2000WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_1:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_2:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.7847 - accuracy: 0.2963 - val_loss: 0.7348 - val_accuracy: 0.3333\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.1975 - val_loss: 0.7100 - val_accuracy: 0.3333\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7044 - accuracy: 0.2222 - val_loss: 0.7015 - val_accuracy: 0.2222\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.2593 - val_loss: 0.6986 - val_accuracy: 0.3333\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.2716 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.2716 - val_loss: 0.6960 - val_accuracy: 0.3333\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.2593 - val_loss: 0.6951 - val_accuracy: 0.3333\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.2840 - val_loss: 0.6946 - val_accuracy: 0.3333\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.2840 - val_loss: 0.6942 - val_accuracy: 0.3333\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.2716 - val_loss: 0.6940 - val_accuracy: 0.3333\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.2716 - val_loss: 0.6939 - val_accuracy: 0.3333\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.2716 - val_loss: 0.6938 - val_accuracy: 0.3333\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.2593 - val_loss: 0.6937 - val_accuracy: 0.3333\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.2840 - val_loss: 0.6936 - val_accuracy: 0.3333\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.2716 - val_loss: 0.6935 - val_accuracy: 0.3333\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.2716 - val_loss: 0.6934 - val_accuracy: 0.3333\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.2593 - val_loss: 0.6934 - val_accuracy: 0.3333\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.2716 - val_loss: 0.6934 - val_accuracy: 0.3333\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.2716 - val_loss: 0.6933 - val_accuracy: 0.3333\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.2963 - val_loss: 0.6933 - val_accuracy: 0.3333\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.2716 - val_loss: 0.6933 - val_accuracy: 0.3333\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.2716 - val_loss: 0.6933 - val_accuracy: 0.3333\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.2593 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2840 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6932 - val_accuracy: 0.3333\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2840 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2593 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2593 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2593 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.2716 - val_loss: 0.6931 - val_accuracy: 0.2222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ87_H5QxOaJ"
      },
      "source": [
        "By ploting the accuracies and loss, I can see how I need to change the number of epochs as the dataset grows. Since each time the application is run, it collects more data to add to the query results dataset for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Qwzurc0FNGu6",
        "outputId": "e165b5cc-4543-43cd-9b0b-0aa45e406a10"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(15, 7), dpi=80)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x560 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBtoRFNfxqrf"
      },
      "source": [
        "This function uses the model to indicate which result is ranked higher than the other result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSBXRgG1xwTN"
      },
      "source": [
        "def perform_rank(result1, result2):\n",
        "  rank = model.predict((np.array([result1[1:]]), np.array([result2[1:]])))\n",
        "  return 1 if rank > 0.5 else (0 if rank == 0.5 else -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM8sWj9Uxymz"
      },
      "source": [
        "This step prompts the user if they would like to enter a query then prompts for a query. It then collects a list of all of the matching articles and associated features relating to the query, article and relationships between the query and article. It then uses the previously trained model to rank the results in order and presents the top 20 results. To increase the speed of the results, the model is only used for top 100 results for term frequency. The top 20 ranked results are then presented to the user and the user is then asked to provide a ranking for that article and query matching. All of these features are then collected for each result and made into a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItNLqddZRHl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940e8b0f-ef96-425a-b137-aae3cec4eea4"
      },
      "source": [
        "import functools\n",
        "\n",
        "rating_data = {\"qid\": [], \"query\": [], \"doc_id\": [], \"rating\": [], \"tf\":  [], \n",
        "               \"p_match\": [], \"complete_count\": [], \"key_size\": [], \n",
        "               \"phrase_count\": [], \"search_size\": [], \"doc_age\": []}\n",
        "qid = 0\n",
        "while(input(\"Do you want a new query(y/n)? \").lower() == 'y'):\n",
        "  qid += 1\n",
        "  search_phrase = input(\"What query do you want to run? \")\n",
        "\n",
        "  search_words = word_tokenize(re.sub(\"[^\\w\\s]\", \"\", search_phrase.lower()))\n",
        "  clean_search = []\n",
        "  for word in search_words:\n",
        "    if word not in stopwords and word.isalpha():\n",
        "      clean_search.append(lemma.lemmatize(word))\n",
        "\n",
        "  (result_list, match_dict), complete_dict = run_search(clean_search)\n",
        "  limited_list = []\n",
        "  # Use term frequency to reduce the list to the top 500 results then use ranknet\n",
        "  # to increase the speed of finding the ranked results\n",
        "  search_limit = 100 if len(result_list) > 100 else len(result_list)\n",
        "  for idx in range(0, search_limit):\n",
        "    doc = result_list[idx][0]\n",
        "    # doc_id tf\tp_match\tcomplete_count\tkey_size\tphrase_count\tsearch_size\tdoc_age\n",
        "    limited_list.append([doc, result_list[idx][1], match_dict[doc], \n",
        "                        complete_dict[doc], df.key_word_count[doc], \n",
        "                        df.key_phase_count[doc], len(clean_search), \n",
        "                        df.ages[doc]])\n",
        "  sorted_results = sorted(limited_list, key=functools.cmp_to_key(perform_rank), reverse=True)\n",
        "\n",
        "  for idx in range(0, 20):\n",
        "    print(sorted_results[idx])\n",
        "    rating = input(\"How do you rate the link {}\".format(df.link[sorted_results[idx][0]]))\n",
        "    rating_data[\"qid\"].append(qid)\n",
        "    rating_data[\"query\"].append(search_phrase)\n",
        "    rating_data[\"doc_id\"].append(sorted_results[idx][0])\n",
        "    rating_data[\"rating\"].append(rating)\n",
        "    rating_data[\"tf\"].append(sorted_results[idx][1])\n",
        "    rating_data[\"p_match\"].append(sorted_results[idx][2])\n",
        "    rating_data[\"complete_count\"].append(sorted_results[idx][3])\n",
        "    rating_data[\"key_size\"].append(sorted_results[idx][4])\n",
        "    rating_data[\"phrase_count\"].append(sorted_results[idx][5])\n",
        "    rating_data[\"search_size\"].append(sorted_results[idx][6])\n",
        "    rating_data[\"doc_age\"].append(sorted_results[idx][7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Do you want a new query(y/n)? y\n",
            "What query do you want to run? identity theft prevention\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_1:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"input_2:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 90, 7) for input Tensor(\"dense_input:0\", shape=(None, 90, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "[8104, 1, 0.3333333333333333, 0, 7, 5, 3, 3]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/embracethelatinx-is-an-all-inclusive-tribute-to-latinos-many-identities_us_59514b21e4b0da2c731d7d790\n",
            "[61, 6, 0.6666666666666666, 0, 103, 20, 3, 5]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/5-identity-theft-facts-th_b_7347248.html4\n",
            "[4286, 3, 0.3333333333333333, 0, 79, 20, 3, 4]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/transbillma-making-transg_b_9161456.html0\n",
            "[4377, 3, 0.3333333333333333, 0, 78, 20, 3, 4]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/new-study-womens-sexual-identity_us_5755dc06e4b0ca5c7b4fca6f0\n",
            "[6562, 3, 1.0, 1, 67, 20, 3, 6]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/heartbleed-free-tool-to-c_us_5bb370fae4b0fa920b98f8793\n",
            "[8093, 3, 0.3333333333333333, 0, 70, 20, 3, 4]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/ana-navarro-to-trump-stop-fighting-broadway-start-fighting-white-supremacists_us_5835a5a3e4b000af95ed5cf80\n",
            "[9074, 3, 0.3333333333333333, 0, 78, 20, 3, 6]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/why-transgender-students-_b_6130100.html0\n",
            "[14510, 3, 0.3333333333333333, 0, 78, 20, 3, 6]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/universal-humanism-or-ide_b_5518416.html0\n",
            "[19097, 3, 0.3333333333333333, 0, 51, 20, 3, 8]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/gender-in-izolyatsia_us_5bb225bce4b0171db69dc8960\n",
            "[8464, 3, 0.3333333333333333, 0, 92, 20, 3, 5]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/developing-resiliency-in-_b_7242718.html0\n",
            "[8553, 3, 0.3333333333333333, 0, 81, 20, 3, 2]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/threat-assessments-crucial-to-prevent-school-shootings_us_5abd0af7e4b075a5c9a465f70\n",
            "[8788, 3, 0.3333333333333333, 0, 82, 20, 3, 6]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/3-strategies-for-building_b_5268583.html0\n",
            "[3041, 2, 0.3333333333333333, 0, 42, 20, 3, 6]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/black-jews_n_5587491.html0\n",
            "[3478, 2, 0.3333333333333333, 0, 64, 20, 3, 3]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/the-irony-in-the-democrats-changing-position-on-abortion_us_598382f9e4b00833d1de269f0\n",
            "[4315, 2, 0.3333333333333333, 0, 87, 20, 3, 8]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/michelle-kosilek-ruling-transgender_us_5bafab29e4b0ad76925fbc510\n",
            "[4409, 2, 0.3333333333333333, 0, 57, 20, 3, 3]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/queer-kid-stuff-asexuality_us_590b84f2e4b0e7021e95d23b0\n",
            "[5289, 2, 0.6666666666666666, 0, 81, 20, 3, 4]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/mastercard-selfie-pay_us_56ce9fd8e4b03260bf758cad3\n",
            "[8246, 2, 0.3333333333333333, 0, 52, 20, 3, 4]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/afro-latina-music-artists-talk-identity-empowerment-and-feminism_us_578d345ce4b0a0ae97c3002c0\n",
            "[9213, 2, 0.3333333333333333, 0, 77, 20, 3, 3]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/the-desirable-american-name_us_586ba0f3e4b04d7df167d74b0\n",
            "[9489, 2, 0.6666666666666666, 0, 9, 5, 3, 5]\n",
            "How do you rate the link https://www.huffingtonpost.com/entry/identity-theft-and-credit-card-fraud-who-is-really-at-risk_b_7471714.html4\n",
            "Do you want a new query(y/n)? n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRc7Uqrdydyf"
      },
      "source": [
        "data = pd.DataFrame(rating_data, columns=rating_data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHmBOr0G1-x3"
      },
      "source": [
        "The following computes the Normalized Cumulative Discounted Gain for the results list based on the ratings provided by the user and the position in the list the ranking occurs. Rankings at the top of the list increase the score more than those at the bottom and these scores for each result are then summed, which is the Discounted Cumulative Gain(DCG) part. Then the scores are normalized by comparing an ideal order of the results to the actual results by taking the list of results and sorting by rating and calculating the DCG. If the results are ordered ideally, then the score is 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ON4kebsvhZ"
      },
      "source": [
        "import math\n",
        "\n",
        "def get_DCG(array):\n",
        "  DCG = 0\n",
        "\n",
        "  for i in range(0, len(array)):\n",
        "    DCG += array[i] / math.log(i + 2, 2)\n",
        "\n",
        "  return DCG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOI0JEaayFp0",
        "outputId": "b3f8e3bf-ee7d-4deb-d70b-8564d45620fe"
      },
      "source": [
        "rank_array = data['rating'].astype('int32').tolist()\n",
        "get_DCG(rank_array) / get_DCG(sorted(rank_array, reverse=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5704743663854617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kImlGcLS3Rcx"
      },
      "source": [
        "The results dataset is now appended to the previously imported dataset that was used to train the model then saved to a csv file to be used again at a later time to better train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVCF4qMjfFEg"
      },
      "source": [
        "max_id = rank_data[\"qid\"].max()\n",
        "for i in range(0, len(data['qid'])):\n",
        "  data['qid'][i] += max_id\n",
        "rank_data = rank_data.append(data, ignore_index = True)\n",
        "rank_data.to_csv('results_ranks.csv', index=False)\n",
        "rank_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}